{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68CTYkjGcdJA",
        "outputId": "9c8ba0ad-9289-4c87-8a95-c42bae27ebfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m76.8/76.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m753.9/753.9 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hPolitica de Precision Mixta activada: mixed_float16\n"
          ]
        }
      ],
      "source": [
        "!pip install -q mlflow pyngrok tensorflow-datasets gradio\n",
        "\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import mlflow\n",
        "from tensorflow.keras import layers, models, applications, optimizers, callbacks\n",
        "from tensorflow.keras import mixed_precision\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# --- CONFIGURACION GLOBAL ---\n",
        "NGROK_AUTH_TOKEN = \"35kIrE6CdClNMjARhepFUEm9bNT_2mEdYtARGGuQnNPVoLNDc\"\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 64  # Aumentado a 64 gracias a Mixed Precision\n",
        "NUM_CLASSES = 101\n",
        "LEARNING_RATE = 0.0001 # Tasa mas baja para ajuste fino\n",
        "EPOCHS = 10      # Mas epocas para el dataset completo\n",
        "RANDOM_SEED = 42\n",
        "MLFLOW_PORT = 5000\n",
        "ARTIFACT_PATH = \"mlflow_artifacts\"\n",
        "\n",
        "# --- OPTIMIZACION DE HARDWARE ---\n",
        "# Configurar politica de precision mixta (acelera entrenamiento y reduce uso de VRAM)\n",
        "try:\n",
        "    policy = mixed_precision.Policy('mixed_float16')\n",
        "    mixed_precision.set_global_policy(policy)\n",
        "    print(\"Politica de Precision Mixta activada: mixed_float16\")\n",
        "except Exception as e:\n",
        "    print(f\"Advertencia: No se pudo activar precision mixta. {e}\")\n",
        "\n",
        "# Establecer semillas\n",
        "tf.random.set_seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def init_mlflow_infrastructure():\n",
        "    \"\"\"\n",
        "    Inicializa el servidor MLflow y gestiona el tunel Ngrok.\n",
        "    Mata procesos zombies para liberar el puerto 5000.\n",
        "    \"\"\"\n",
        "    print(\"Configurando infraestructura de seguimiento...\")\n",
        "\n",
        "    # 1. Limpieza de procesos\n",
        "    get_ipython().system_raw(\"pkill -f mlflow\")\n",
        "    ngrok.kill()\n",
        "\n",
        "    # 2. Configuracion de red\n",
        "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "    if not os.path.exists(ARTIFACT_PATH):\n",
        "        os.makedirs(ARTIFACT_PATH)\n",
        "\n",
        "    # 3. Lanzar demonio MLflow\n",
        "    # Redirigimos stderr a null para mantener limpia la celda\n",
        "    get_ipython().system_raw(f\"nohup mlflow ui --port {MLFLOW_PORT} > /dev/null 2>&1 &\")\n",
        "    time.sleep(5)\n",
        "\n",
        "    # 4. Establecer tunel seguro\n",
        "    try:\n",
        "        public_url = ngrok.connect(MLFLOW_PORT, bind_tls=True, host_header=\"rewrite\")\n",
        "        print(f\"Panel MLflow disponible en: {public_url}\")\n",
        "        mlflow.set_tracking_uri(f\"http://127.0.0.1:{MLFLOW_PORT}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Fallo critico al iniciar Ngrok: {e}\")\n",
        "\n",
        "init_mlflow_infrastructure()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kscXAYuGdxy5",
        "outputId": "60604dbe-86e1-45a9-db38-4946f60c73a7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configurando infraestructura de seguimiento...\n",
            "Panel MLflow disponible en: NgrokTunnel: \"https://sabina-unhardenable-tellingly.ngrok-free.dev\" -> \"http://localhost:5000\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_pipeline(image, label):\n",
        "    \"\"\"\n",
        "    Funcion ETL mapeada a traves del dataset.\n",
        "    Optimizado para rendimiento en GPU.\n",
        "    \"\"\"\n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    label = tf.one_hot(label, NUM_CLASSES)\n",
        "    return image, label\n",
        "\n",
        "def load_full_dataset():\n",
        "    \"\"\"\n",
        "    Carga el dataset Food-101 completo (5GB).\n",
        "    Utiliza estrategias de caching y prefetching para manejar grandes volumenes.\n",
        "    \"\"\"\n",
        "    print(\"Iniciando descarga/carga de Food-101 (5GB). Esto puede tomar tiempo...\")\n",
        "\n",
        "    # Carga sin slicing para obtener el dataset completo\n",
        "    (ds_train, ds_val), ds_info = tfds.load(\n",
        "        'food101',\n",
        "        split=['train', 'validation'],\n",
        "        shuffle_files=True,\n",
        "        as_supervised=True,\n",
        "        with_info=True\n",
        "    )\n",
        "\n",
        "    autotune = tf.data.AUTOTUNE\n",
        "\n",
        "    # Pipeline de Entrenamiento\n",
        "    # 1. Map: Preprocesamiento paralelo\n",
        "    # 2. Shuffle: Mezcla buffer de 1000 elementos\n",
        "    # 3. Batch: Agrupa en lotes\n",
        "    # 4. Prefetch: Prepara el siguiente lote en background\n",
        "    ds_train = ds_train.map(preprocess_pipeline, num_parallel_calls=autotune)\n",
        "    ds_train = ds_train.shuffle(1000).batch(BATCH_SIZE).prefetch(autotune)\n",
        "\n",
        "    # Pipeline de Validacion (Sin shuffle)\n",
        "    ds_val = ds_val.map(preprocess_pipeline, num_parallel_calls=autotune)\n",
        "    ds_val = ds_val.batch(BATCH_SIZE).prefetch(autotune)\n",
        "\n",
        "    return ds_train, ds_val, ds_info\n",
        "\n",
        "# Cargar datos\n",
        "train_ds, val_ds, dataset_info = load_full_dataset()\n",
        "class_names = dataset_info.features['label'].names\n",
        "print(f\"Pipeline ETL listo. Total imagenes de entrenamiento: {dataset_info.splits['train'].num_examples}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "c267ff4a2c9c43019bd86d5436d65bd4",
            "d46e4e5a34b4413dbc5cd2e012cf29e8",
            "c5eb58d2f91d42f0ae8144a0b3b70803",
            "d46aaa3f05054f168014e999784c6ab2",
            "38a662a9b063488c932deb1a494d3e2f",
            "5b3fe45c00654c85bd34125c91027251",
            "88faa033176a423e883428fa9e9373bb",
            "8f984ac95da446d4b70014935e39b342",
            "2bda6f7e7e3e4c49a52b1ed049c73e19",
            "9ec176adac704f34b173688641ed8250",
            "4b930c9de4464c3a936b3e6dba83a486",
            "846f53add7c84c3599b16b576ff6cdd0",
            "779a880eaef64dcfbb6489d69a4f1813",
            "d3d415dac4ef45ec879c8cb042ec64cf",
            "51b3007170b5460cbc99e6c30383f4e9",
            "0bc531164f0c4139ad2f554f4d85e8ad",
            "2ff5f3092f0f44db8f4baadd2330daeb",
            "b749ad8571cd4688a2362c9d432ebc19",
            "4087aadbf75c4d3295fe225f72ff01c2",
            "5820b684d92d42b1b95b7447e07dcf09",
            "6fc45298db6044a5ac9d64c8249aa2f7",
            "60eb3c98f67644628e76280d19d5e870",
            "b6c0286ce4d14710a597d6defedb4d4a",
            "f5159e271713455f8ef2367837611e2b",
            "0086bd17c4e344e1ae9181202e8d40d3",
            "c481b78ab5764b9d922f1d17aa3a8825",
            "5a2459b71c854da8a4c11bf39e762990",
            "2eb2a124b1034ff593bdc9b9511d9721",
            "6cc9e326c416431aacca50113f02510d",
            "8c81d68923d84a55af2ddb759252ef86",
            "685a7ea75c9d4128be3552dae2c7eb1b",
            "75831c74d05b4a519d5b6b82b1d00a84",
            "c2dd61c7a6d1494089985b40926c51c4",
            "c1d74e3b06eb4bb5bf024b93ead13c1a",
            "b33990eb8520497e9f3b684174da364d",
            "8fd4bad6a6254a6281891d7e54d5d5f4",
            "7f7b2db284124f66b9bf3b855f433ba6",
            "cd3f1d03102049e4a13950c74c87f410",
            "0899709d15c44d48a579df3752f18c31",
            "7442c49e02134cd5b7994e7ef7a0bb89",
            "285d5d98e94b45fd91666c136d61cd9e",
            "40f02b52200649b99e251a470a30ec1d",
            "f4ba2e16d2574aeeaf979fab5a1d75f3",
            "d8714f189f024740948baae1c21ce2a6",
            "8bad4946450e4f85bdf64aa4170666bc",
            "0d9567f40d2540a68715397a9f1ee6cb",
            "a1d052c4835e4fd48d86e19536ff7f15",
            "0fb272d9e94644108e050abac006890f",
            "2692be0a0f6f4e0dbd6a393ae73124bc",
            "f914948ab28d43278068e75f2837604f",
            "395b8b7a771a493da6882748f730c823",
            "35d1bb500baf4529b2ac655ef6b8c8a3",
            "89414bd4165f463088294dacaf6f1cd1",
            "7a2478b86a414be28155ab8ad8bb73ea",
            "7ac06f2a30b14710883193152108ebbe",
            "a7a4314845354a68a07b00ea4a314e45",
            "74a414e73aee420291acc5f5604ebfe7",
            "bfb1d5a505784fe2ad521670b15b11b8",
            "768c9ca60e2a4b938cbfd4d19f43902b",
            "188859c213094efa9348a058251b7c42",
            "9f632755626f429ca0c4f207fdb9d3ca",
            "586e216467d0484d884ab51845bca548",
            "49f6ac17530a4d97bbc8b6e8e66748a7",
            "51d8244ca48d4c68a682f8765d324b6b",
            "60584685032c4aff8e61b556901ec5ac",
            "25b23713fa734799ac4ae3e3ae22dcb1",
            "f1eae1ed95ef4e55b194f43b94c4a0da",
            "f23f3db5412043e2ba6d5a91b46bc47b",
            "ddb4fac31cf84d1e8c9f80b9e4e8f650",
            "4f9e3d0b3cde4f96b735c928f365903c",
            "4f0655f7dffb4812b33bc7bedcc5e18e",
            "558069e526e4434388e3c12eeac81204",
            "274d01d847fd4a1db7c2291cc4953813",
            "9caf5fcefbc7495fa1e238f5ca62b764",
            "9cf5a38aa94242bd8480fe59c047a96d",
            "b5609ca808884503a2ef93825473fbcd",
            "d7a09bbe46f84f65b8a1e090b92f4d04",
            "a01c1ba99f964a508dcfe07675439b8c",
            "b0701049b3a949729a05f655852372c3",
            "b9a3040f82344c379e64ab625176cba8",
            "6a9f686b6b304b91a81e39e3f0f8ff18",
            "d44814fc8f934c1a9f634a4931d51195",
            "fbd3a5721da6444cab8e050c93cd58be",
            "b765e43336494171aeae0e52e020c6c5",
            "d6a52264589e434b8420d2f1ac67949c",
            "95ad5d2222a6449d93cbafccfd4fc463",
            "0bca89eb9ee348f5aee3ec12f78c210d",
            "5755254752cb4b27a9d7bddf1565245a"
          ]
        },
        "id": "wA4U45ntePmq",
        "outputId": "7f7f2a15-1b83-41e9-8299-bef4658e4cf7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando descarga/carga de Food-101 (5GB). Esto puede tomar tiempo...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Variant folder /root/tensorflow_datasets/food101/2.0.0 has no dataset_info.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /root/tensorflow_datasets/food101/2.0.0...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Completed...: 0 url [00:00, ? url/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c267ff4a2c9c43019bd86d5436d65bd4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Size...: 0 MiB [00:00, ? MiB/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "846f53add7c84c3599b16b576ff6cdd0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extraction completed...: 0 file [00:00, ? file/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b6c0286ce4d14710a597d6defedb4d4a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1d74e3b06eb4bb5bf024b93ead13c1a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train examples...: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8bad4946450e4f85bdf64aa4170666bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Shuffling /root/tensorflow_datasets/food101/incomplete.A9TBTK_2.0.0/food101-train.tfrecord*...:   0%|         \u2026"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a7a4314845354a68a07b00ea4a314e45"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation examples...: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1eae1ed95ef4e55b194f43b94c4a0da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Shuffling /root/tensorflow_datasets/food101/incomplete.A9TBTK_2.0.0/food101-validation.tfrecord*...:   0%|    \u2026"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a01c1ba99f964a508dcfe07675439b8c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset food101 downloaded and prepared to /root/tensorflow_datasets/food101/2.0.0. Subsequent calls will reuse this data.\n",
            "Pipeline ETL listo. Total imagenes de entrenamiento: 75750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_production_model():\n",
        "    \"\"\"\n",
        "    Construye modelo MobileNetV2 adaptado para 101 clases.\n",
        "    \"\"\"\n",
        "    base_model = applications.MobileNetV2(\n",
        "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "    # Importante: MobileNetV2 tiene capas BatchNormalization que deben mantenerse\n",
        "    # en modo inferencia incluso si descongelamos pesos.\n",
        "    base_model.trainable = False\n",
        "\n",
        "    inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(0.3)(x) # Aumentado dropout para dataset grande\n",
        "\n",
        "    # Capa de salida debe ser float32 expl\u00edcitamente cuando se usa mixed_precision\n",
        "    outputs = layers.Dense(NUM_CLASSES, activation='softmax', dtype='float32')(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs, name=\"Food101_Production_V1\")\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def get_callbacks():\n",
        "    \"\"\"\n",
        "    Define estrategias de control de entrenamiento.\n",
        "    \"\"\"\n",
        "    early_stop = callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=3,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    return [early_stop]\n",
        "\n",
        "print(\"Arquitectura y callbacks definidos.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zyS_KZLhBFa",
        "outputId": "6450b5cb-3a94-486a-cc98-01790a580b6c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquitectura y callbacks definidos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_full_experiment(run_name=\"Full_Food101_Training\"):\n",
        "\n",
        "    mlflow.set_experiment(\"Food101_Production_Scale\")\n",
        "\n",
        "    with mlflow.start_run(run_name=run_name) as run:\n",
        "        print(f\"--- Iniciando Run: {run_name} ---\")\n",
        "\n",
        "        mlflow.tensorflow.autolog(log_models=True)\n",
        "\n",
        "        model = build_production_model()\n",
        "        my_callbacks = get_callbacks()\n",
        "\n",
        "        # Entrenamiento\n",
        "        # Nota: Al ser dataset completo, cada epoca tomara varios minutos\n",
        "        history = model.fit(\n",
        "            train_ds,\n",
        "            validation_data=val_ds,\n",
        "            epochs=EPOCHS,\n",
        "            callbacks=my_callbacks,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        print(f\"Run completado. ID: {run.info.run_id}\")\n",
        "        return model\n",
        "\n",
        "# Ejecutar el entrenamiento principal\n",
        "# Asegurate de tener la GPU activada en Colab (Runtime > Change runtime type > T4 GPU)\n",
        "final_model = run_full_experiment(run_name=\"MobileNet_FullDataset_v1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "id": "sKFTB-rnhDHd",
        "outputId": "a3700119-0a9e-477a-dc27-fbf6ea735d3e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/11/30 02:03:17 INFO mlflow.tracking.fluent: Experiment with name 'Food101_Production_Scale' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Iniciando Run: MobileNet_FullDataset_v1 ---\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1184/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.0906 - loss: 4.2709"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1184/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 218ms/step - accuracy: 0.0907 - loss: 4.2704 - val_accuracy: 0.4037 - val_loss: 2.6432\n",
            "Epoch 2/10\n",
            "\u001b[1m1183/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u2501\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.3404 - loss: 2.7750"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1184/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 201ms/step - accuracy: 0.3405 - loss: 2.7749 - val_accuracy: 0.4887 - val_loss: 2.1457\n",
            "Epoch 3/10\n",
            "\u001b[1m1184/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.4188 - loss: 2.3816"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1184/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 201ms/step - accuracy: 0.4188 - loss: 2.3816 - val_accuracy: 0.5248 - val_loss: 1.9406\n",
            "Epoch 4/10\n",
            "\u001b[1m1184/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.4586 - loss: 2.1965"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1184/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 167ms/step - accuracy: 0.4586 - loss: 2.1965 - val_accuracy: 0.5453 - val_loss: 1.8282\n",
            "Epoch 5/10\n",
            "\u001b[1m1184/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.4796 - loss: 2.0855"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1184/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 157ms/step - accuracy: 0.4796 - loss: 2.0855 - val_accuracy: 0.5596 - val_loss: 1.7524\n",
            "Epoch 6/10\n",
            "\u001b[1m1183/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u2501\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.4993 - loss: 2.0048"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1184/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 168ms/step - accuracy: 0.4993 - loss: 2.0048 - val_accuracy: 0.5696 - val_loss: 1.7031\n",
            "Epoch 7/10\n",
            "\u001b[1m1184/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5115 - loss: 1.9441"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1184/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 156ms/step - accuracy: 0.5115 - loss: 1.9441 - val_accuracy: 0.5775 - val_loss: 1.6650\n",
            "Epoch 8/10\n",
            "\u001b[1m1184/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.5240 - loss: 1.8899"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1184/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 157ms/step - accuracy: 0.5240 - loss: 1.8899 - val_accuracy: 0.5820 - val_loss: 1.6367\n",
            "Epoch 9/10\n",
            "\u001b[1m1184/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.5305 - loss: 1.8601"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1184/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 157ms/step - accuracy: 0.5305 - loss: 1.8601 - val_accuracy: 0.5871 - val_loss: 1.6108\n",
            "Epoch 10/10\n",
            "\u001b[1m1183/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u2501\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.5362 - loss: 1.8262"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1184/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 165ms/step - accuracy: 0.5362 - loss: 1.8262 - val_accuracy: 0.5914 - val_loss: 1.5923\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/11/30 02:42:26 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run completado. ID: c4244dfd47164bb4bae9d201f5ffd729\n",
            "\ud83c\udfc3 View run MobileNet_FullDataset_v1 at: http://127.0.0.1:5000/#/experiments/202097377562280212/runs/c4244dfd47164bb4bae9d201f5ffd729\n",
            "\ud83e\uddea View experiment at: http://127.0.0.1:5000/#/experiments/202097377562280212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def predict_service(image):\n",
        "    if image is None:\n",
        "        return \"Error: No image provided\"\n",
        "\n",
        "    # Preprocesamiento\n",
        "    img_array = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "    img_array = tf.cast(img_array, tf.float32) / 255.0\n",
        "    img_array = tf.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Inferencia\n",
        "    t_start = time.time()\n",
        "    predictions = final_model.predict(img_array, verbose=0)\n",
        "    inference_time = time.time() - t_start\n",
        "\n",
        "    # Post-procesamiento\n",
        "    score = tf.nn.softmax(predictions[0])\n",
        "    top_3_indices = np.argsort(predictions[0])[::-1][:3]\n",
        "\n",
        "    result = {}\n",
        "    for i in top_3_indices:\n",
        "        class_name = class_names[i]\n",
        "        confidence = float(predictions[0][i])\n",
        "        result[class_name] = confidence\n",
        "\n",
        "    return result, f\"{inference_time:.4f} seg\"\n",
        "\n",
        "# Definicion de UI\n",
        "iface = gr.Interface(\n",
        "    fn=predict_service,\n",
        "    inputs=gr.Image(label=\"Imagen de Entrada\"),\n",
        "    outputs=[\n",
        "        gr.Label(num_top_classes=3, label=\"Clasificacion\"),\n",
        "        gr.Number(label=\"Tiempo de Inferencia\")\n",
        "    ],\n",
        "    title=\"Sistema de Reconocimiento Food-101\",\n",
        "    description=\"Modelo entrenado en 75,750 imagenes. Sube una foto de comida.\",\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "iface.launch(share=True, debug=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "dG2bDRhBhTpX",
        "outputId": "97c1c976-1322-4abc-e4ac-280661303da1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gradio/interface.py:415: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated. Use `flagging_mode` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://94aed32d3d1a065d0d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://94aed32d3d1a065d0d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Liberacion de recursos\n",
        "ngrok.kill()\n",
        "get_ipython().system_raw(\"pkill -f mlflow\")\n",
        "print(\"Sesion finalizada y puertos liberados.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwdSHFcWsGGb",
        "outputId": "001f062d-4be1-43da-ea39-29b806ce5936"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sesion finalizada y puertos liberados.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# 1. Matar cualquier proceso zombi anterior\n",
        "print(\"\ud83d\ude91 Reviviendo el servidor MLflow...\")\n",
        "get_ipython().system_raw(\"pkill -f mlflow\")\n",
        "ngrok.kill()\n",
        "\n",
        "# 2. Tu Token (Aseg\u00farate de que sea el correcto)\n",
        "NGROK_AUTH_TOKEN = \"35kIrE6CdClNMjARhepFUEm9bNT_2mEdYtARGGuQnNPVoLNDc\"\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "# 3. Lanzar MLflow de nuevo\n",
        "# Usamos nohup para que sobreviva en background\n",
        "get_ipython().system_raw(\"nohup mlflow ui --port 5000 > mlflow.log 2>&1 &\")\n",
        "time.sleep(5) # Esperar a que arranque\n",
        "\n",
        "# 4. Reconectar Ngrok\n",
        "try:\n",
        "    public_url = ngrok.connect(5000, bind_tls=True, host_header=\"rewrite\")\n",
        "    print(f\"\u2705 Servidor operativo de nuevo: {public_url}\")\n",
        "except Exception as e:\n",
        "    print(f\"\u274c Error al reconectar: {e}\")\n",
        "\n",
        "# 5. Importante: Decirle a Python d\u00f3nde est\u00e1 el servidor\n",
        "import mlflow\n",
        "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOW2daaoy4y_",
        "outputId": "a35877a2-e017-4c88-81a3-de84f930abfb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\ud83d\ude91 Reviviendo el servidor MLflow...\n",
            "\u2705 Servidor operativo de nuevo: NgrokTunnel: \"https://sabina-unhardenable-tellingly.ngrok-free.dev\" -> \"http://localhost:5000\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- FASE 2: FINE-TUNING (AJUSTE FINO) ---\n",
        "\n",
        "import tensorflow as tf\n",
        "import mlflow\n",
        "\n",
        "def run_finetuning(model_base, initial_epochs=10, new_epochs=10):\n",
        "\n",
        "    # 1. Configurar MLflow para la nueva fase\n",
        "    mlflow.set_experiment(\"Food101_Optimization\")\n",
        "\n",
        "    with mlflow.start_run(run_name=\"MobileNetV2_FineTuning_Top50\") as run:\n",
        "        print(f\"--- Iniciando Fine-Tuning: {run.info.run_name} ---\")\n",
        "\n",
        "        # 2. Descongelar el modelo base\n",
        "        # En nuestra arquitectura, la capa [1] es el MobileNetV2\n",
        "        base_model = model_base.layers[1]\n",
        "        base_model.trainable = True\n",
        "\n",
        "        print(f\"Capas totales en MobileNetV2: {len(base_model.layers)}\")\n",
        "\n",
        "        # Congelar todas las capas EXCEPTO las ultimas 50\n",
        "        # Esto permite adaptar solo las caracteristicas de alto nivel (texturas de comida)\n",
        "        fine_tune_at = len(base_model.layers) - 50\n",
        "        for layer in base_model.layers[:fine_tune_at]:\n",
        "            layer.trainable = False\n",
        "\n",
        "        print(f\"Descongelando desde la capa {fine_tune_at} hacia adelante.\")\n",
        "\n",
        "        # 3. Re-compilar con Learning Rate MUY BAJO (Crucial)\n",
        "        # Usamos 1e-5 (0.00001) para no destruir los pesos pre-entrenados\n",
        "        model_base.compile(\n",
        "            optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        # Activar log automatico\n",
        "        mlflow.tensorflow.autolog(log_models=True)\n",
        "\n",
        "        # 4. Continuar el entrenamiento\n",
        "        # 'initial_epoch' asegura que las graficas de Loss sigan donde se quedaron\n",
        "        total_epochs = initial_epochs + new_epochs\n",
        "\n",
        "        history_fine = model_base.fit(\n",
        "            train_ds,\n",
        "            validation_data=val_ds,\n",
        "            epochs=total_epochs,\n",
        "            initial_epoch=initial_epochs,\n",
        "            callbacks=get_callbacks(), # Usamos los mismos callbacks (EarlyStopping)\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        print(f\"Fine-Tuning completado. ID: {run.info.run_id}\")\n",
        "        return model_base, history_fine\n",
        "\n",
        "# Ejecutar la mejora\n",
        "# Asegurate de que 'final_model' esta cargado en memoria de la fase anterior\n",
        "# Si se desconecto el entorno, tendras que volver a cargar/entrenar la fase 1 primero.\n",
        "if 'final_model' in locals():\n",
        "    improved_model, history_ft = run_finetuning(final_model, initial_epochs=10, new_epochs=10)\n",
        "else:\n",
        "    print(\"Error: No se encuentra 'final_model'. Por favor ejecuta la fase 1 (Entrenamiento Base) primero.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 831
        },
        "id": "kL2cXQHEye1a",
        "outputId": "8791fb9f-776e-47c7-e8ef-a855973eab52"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=6, read=7, redirect=7, status=7)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x78b776e6f0b0>: Failed to establish a new connection: [Errno 111] Connection refused')': /api/2.0/mlflow/experiments/get-by-name?experiment_name=Food101_Optimization\n",
            "WARNING:pyngrok.process.ngrok:t=2025-11-30T03:26:01+0000 lvl=warn msg=\"failed to open private leg\" id=d15ee6df31bd privaddr=localhost:5000 err=\"dial tcp [::1]:5000: connect: connection refused\"\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=5, connect=5, read=7, redirect=7, status=7)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x78b774240890>: Failed to establish a new connection: [Errno 111] Connection refused')': /api/2.0/mlflow/experiments/get-by-name?experiment_name=Food101_Optimization\n",
            "2025/11/30 03:26:05 INFO mlflow.tracking.fluent: Experiment with name 'Food101_Optimization' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Iniciando Fine-Tuning: MobileNetV2_FineTuning_Top50 ---\n",
            "Capas totales en MobileNetV2: 154\n",
            "Descongelando desde la capa 104 hacia adelante.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/20\n",
            "\u001b[1m1184/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.4211 - loss: 2.4005"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1184/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 230ms/step - accuracy: 0.4211 - loss: 2.4003 - val_accuracy: 0.6024 - val_loss: 1.5134\n",
            "Epoch 12/20\n",
            "\u001b[1m1183/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u2501\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.5514 - loss: 1.7580"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1184/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 174ms/step - accuracy: 0.5515 - loss: 1.7580 - val_accuracy: 0.6294 - val_loss: 1.4009\n",
            "Epoch 13/20\n",
            "\u001b[1m1183/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u2501\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.5926 - loss: 1.5858"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1184/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 162ms/step - accuracy: 0.5926 - loss: 1.5858 - val_accuracy: 0.6471 - val_loss: 1.3180\n",
            "Epoch 14/20\n",
            "\u001b[1m1183/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u2501\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.6192 - loss: 1.4602"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1184/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 164ms/step - accuracy: 0.6192 - loss: 1.4602 - val_accuracy: 0.6633 - val_loss: 1.2521\n",
            "Epoch 15/20\n",
            "\u001b[1m1184/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.6410 - loss: 1.3734"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1184/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 173ms/step - accuracy: 0.6410 - loss: 1.3734 - val_accuracy: 0.6757 - val_loss: 1.2061\n",
            "Epoch 16/20\n",
            "\u001b[1m1183/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u2501\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.6610 - loss: 1.2943"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1184/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 160ms/step - accuracy: 0.6610 - loss: 1.2942 - val_accuracy: 0.6834 - val_loss: 1.1662\n",
            "Epoch 17/20\n",
            "\u001b[1m1184/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.6771 - loss: 1.2264"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1184/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 205ms/step - accuracy: 0.6771 - loss: 1.2263 - val_accuracy: 0.6907 - val_loss: 1.1382\n",
            "Epoch 18/20\n",
            "\u001b[1m1183/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u2501\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.6913 - loss: 1.1582"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1184/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 173ms/step - accuracy: 0.6913 - loss: 1.1582 - val_accuracy: 0.6966 - val_loss: 1.1156\n",
            "Epoch 19/20\n",
            "\u001b[1m1183/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u2501\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7057 - loss: 1.1009"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1184/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 171ms/step - accuracy: 0.7057 - loss: 1.1009 - val_accuracy: 0.7021 - val_loss: 1.0943\n",
            "Epoch 20/20\n",
            "\u001b[1m1183/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u2501\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.7194 - loss: 1.0466"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1184/1184\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 169ms/step - accuracy: 0.7194 - loss: 1.0466 - val_accuracy: 0.7074 - val_loss: 1.0767\n",
            "Restoring model weights from the end of the best epoch: 20.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/11/30 04:07:23 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-Tuning completado. ID: a358632e28a04da987219026574ff20e\n",
            "\ud83c\udfc3 View run MobileNetV2_FineTuning_Top50 at: http://127.0.0.1:5000/#/experiments/178703244249790697/runs/a358632e28a04da987219026574ff20e\n",
            "\ud83e\uddea View experiment at: http://127.0.0.1:5000/#/experiments/178703244249790697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- DESPLIEGUE FINAL (GRADIO) ---\n",
        "import gradio as gr\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# 1. Asegurarnos de usar el mejor modelo disponible en memoria\n",
        "# Tu funci\u00f3n devolvi\u00f3 el modelo entrenado, vamos a usar ese.\n",
        "if 'improved_model' in locals():\n",
        "    model_para_demo = improved_model\n",
        "    print(\"\u2705 CARGADO: Modelo Optimizado (Fine-Tuning ~70% acc)\")\n",
        "elif 'final_model' in locals():\n",
        "    model_para_demo = final_model\n",
        "    print(\"\u26a0\ufe0f AVISO: Usando modelo base (Fase 1). Si hiciste Fine-Tuning, aseg\u00farate de haber asignado el resultado a una variable.\")\n",
        "else:\n",
        "    print(\"\u274c ERROR: No hay modelo en memoria. Ejecuta el entrenamiento primero.\")\n",
        "\n",
        "# 2. Funci\u00f3n de Predicci\u00f3n (La l\u00f3gica del cerebro)\n",
        "def predecir_plato(imagen):\n",
        "    if imagen is None:\n",
        "        return None\n",
        "\n",
        "    # Preprocesar igual que en el entrenamiento\n",
        "    img = tf.image.resize(imagen, (224, 224))\n",
        "    img = tf.cast(img, tf.float32) / 255.0\n",
        "    img = tf.expand_dims(img, axis=0)\n",
        "\n",
        "    # Predecir\n",
        "    predicciones = model_para_demo.predict(img)\n",
        "\n",
        "    # Obtener las 3 clases m\u00e1s probables\n",
        "    top_3_indices = np.argsort(predicciones[0])[::-1][:3]\n",
        "\n",
        "    resultado = {}\n",
        "    for i in top_3_indices:\n",
        "        nombre_clase = class_names[i] # Usamos la lista de nombres que cargamos al inicio\n",
        "        confianza = float(predicciones[0][i])\n",
        "        resultado[nombre_clase] = confianza\n",
        "\n",
        "    return resultado\n",
        "\n",
        "# 3. Interfaz Visual\n",
        "demo = gr.Interface(\n",
        "    fn=predecir_plato,\n",
        "    inputs=gr.Image(type=\"numpy\", label=\"Sube una foto de comida\"),\n",
        "    outputs=gr.Label(num_top_classes=3, label=\"Top 3 Predicciones\"),\n",
        "    title=\"\ud83c\udf54 Food-101 Classifier (MobileNetV2 Fine-Tuned)\",\n",
        "    description=\"Modelo de IA optimizado capaz de reconocer 101 tipos de comida con un 70% de precisi\u00f3n.\",\n",
        "    theme=\"soft\"\n",
        ")\n",
        "\n",
        "# 4. Lanzar (Genera link p\u00fablico)\n",
        "print(\"Generando enlace p\u00fablico...\")\n",
        "demo.launch(share=True, debug=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "g1lg-bfI-uXO",
        "outputId": "ef29482c-2be6-4bbc-f698-5bedaf4bc7a6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u2705 CARGADO: Modelo Optimizado (Fine-Tuning ~70% acc)\n",
            "Generando enlace p\u00fablico...\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://c71fe7b8def6227be4.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c71fe7b8def6227be4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}